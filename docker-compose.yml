networks:
    iceberg-net:
volumes:
  minio-s3-data:

services:
  pg-catalog:
    image: postgres:15-alpine
    container_name: pg-catalog
    environment:
      - POSTGRES_USER=iceberg
      - POSTGRES_PASSWORD=iceberg
      - POSTGRES_DB=iceberg
    networks:
      iceberg-net:
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "iceberg" ]
      interval: 5s
      retries: 5
    ports:
      - "5432:5432"

  spark-master:
    image: apache/spark:latest
    container_name: spark-master
    volumes:
      - ./spark-apps:/opt/spark/apps
      - ./spark-logs:/tmp/spark-events
      - ./spark/jars:/opt/spark/work-dir/jars
      - ./spark/conf:/opt/spark/work-dir/conf
    networks:
      iceberg-net:
    depends_on:
      minio-s3:
        condition: service_healthy
      pg-catalog:
        condition: service_healthy
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    entrypoint: >
      /bin/sh -c "
      cp  /opt/spark/work-dir/jars/*.jar /opt/spark/jars;
      mkdir /opt/spark/conf;
      cp /opt/spark/work-dir/conf/spark-defaults.conf /opt/spark/conf/spark-defaults.conf;
      /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master;
      "
    ports:
      - 7077:7077
      - 8080:8080
      - 10000:10000
      - 10001:10001

  spark-worker-1:
    image: apache/spark:latest
    container_name: spark-worker-1
    volumes:
      - ./spark-apps:/opt/spark/apps
      - ./spark-logs:/tmp/spark-events
      - ./spark/jars:/opt/spark/work-dir/jars
      - ./spark/conf:/opt/spark/work-dir/conf
    depends_on:
      - spark-master
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    networks:
      iceberg-net:
    entrypoint: >
      /bin/sh -c "
      cp  /opt/spark/work-dir/jars/*.jar /opt/spark/jars;
      mkdir /opt/spark/conf;
      cp /opt/spark/work-dir/conf/spark-defaults.conf /opt/spark/conf/spark-defaults.conf;
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark-master:7077 
      "
  spark-worker-2:
    image: apache/spark:latest
    container_name: spark-worker-2
    volumes:
      - ./spark-apps:/opt/spark/apps
      - ./spark-logs:/tmp/spark-events
      - ./spark/jars:/opt/spark/work-dir/jars
      - ./spark/conf:/opt/spark/work-dir/conf
    depends_on:
      - spark-master
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    networks:
      iceberg-net:
    entrypoint: >
      /bin/sh -c "
      cp  /opt/spark/work-dir/jars/*.jar /opt/spark/jars;
      mkdir /opt/spark/conf;
      cp /opt/spark/work-dir/conf/spark-defaults.conf /opt/spark/conf/spark-defaults.conf;
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark-master:7077 
      "

  minio-s3:
    image: minio/minio
    container_name: minio-s3
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
      - MINIO_DOMAIN=minio
    command: ["server", "/data", "--console-address", ":9001"]
    networks:
      iceberg-net:
        aliases:
          - warehouse.minio
    volumes:
      - minio-s3-data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 30s
      timeout: 20s
      retries: 3

  mc:
    depends_on:
      - minio-s3
    image: minio/mc
    container_name: mc
    networks:
      iceberg-net:
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    entrypoint: >
      /bin/sh -c "
      sleep 10;
      until (/usr/bin/mc config host add minio http://minio-s3:9000 admin password --api S3v4 --lookup auto) do echo '...waiting...' && sleep 1; done;
      /usr/bin/mc rm -r --force minio/warehouse;
      /usr/bin/mc mb minio/warehouse;
      /usr/bin/mc policy set public minio/warehouse;
      exit 0
      "

